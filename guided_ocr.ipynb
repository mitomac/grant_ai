{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided OCR with Structure Recognition\n",
    "\n",
    "This notebook focuses on Phase 1 of our enhanced OCR process: identifying the document structure from PDF page images.\n",
    "\n",
    "## Steps:\n",
    "1. Convert PDF to page images\n",
    "2. Send images to Claude 3.7 Sonnet API\n",
    "3. Have Claude identify hierarchical heading structure\n",
    "4. Create a structural map of the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Any\n",
    "import anthropic\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Set your API key\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    print(\"Warning: No Anthropic API key found. Set the ANTHROPIC_API_KEY environment variable.\")\n",
    "    # Uncomment and set directly if needed\n",
    "    # ANTHROPIC_API_KEY = \"your_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Models for Document Structure\n",
    "\n",
    "We'll use Pydantic models to structure our document data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadingElement(BaseModel):\n",
    "    \"\"\"A heading element in the document\"\"\"\n",
    "    text: str = Field(..., description=\"The heading text\")\n",
    "    level: int = Field(..., description=\"Heading level (1 for main headings, 2 for subheadings, etc.)\")\n",
    "    page: int = Field(..., description=\"Page number containing the heading (1-indexed)\")\n",
    "    position: Optional[Dict[str, int]] = Field(None, description=\"Position coordinates on page (x, y, width, height)\")\n",
    "\n",
    "class DocumentStructure(BaseModel):\n",
    "    \"\"\"Structure of the document extracted from images\"\"\"\n",
    "    headings: List[HeadingElement] = Field(default_factory=list, description=\"All headings in the document\")\n",
    "    total_pages: int = Field(..., description=\"Total number of pages in the document\")\n",
    "    document_title: Optional[str] = Field(None, description=\"Title of the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing Functions\n",
    "\n",
    "These functions handle the conversion of PDF to images and preparation for API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, dpi=200):\n",
    "    \"\"\"\n",
    "    Convert PDF to a list of PIL Image objects.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        dpi: Resolution for the images (higher = better quality but larger size)\n",
    "        \n",
    "    Returns:\n",
    "        List of PIL Image objects\n",
    "    \"\"\"\n",
    "    print(f\"Converting PDF to images: {pdf_path}\")\n",
    "    images = convert_from_path(pdf_path, dpi=dpi)\n",
    "    print(f\"Converted {len(images)} pages\")\n",
    "    return images\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    \"\"\"\n",
    "    Encode a PIL Image to base64 for API transmission.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        \n",
    "    Returns:\n",
    "        Base64 encoded string\n",
    "    \"\"\"\n",
    "    import io\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def prepare_images_for_api(images, max_images=None):\n",
    "    \"\"\"\n",
    "    Prepare images for the Anthropic API by encoding them to base64.\n",
    "    \n",
    "    Args:\n",
    "        images: List of PIL Image objects\n",
    "        max_images: Maximum number of images to process (None = all)\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with page number and base64 data\n",
    "    \"\"\"\n",
    "    if max_images is not None:\n",
    "        images = images[:max_images]\n",
    "        \n",
    "    encoded_images = []\n",
    "    for i, img in enumerate(images):\n",
    "        encoded_images.append({\n",
    "            \"page_number\": i + 1,  # 1-indexed page numbers\n",
    "            \"base64\": encode_image_to_base64(img)\n",
    "        })\n",
    "        \n",
    "    return encoded_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Extraction Using Claude API\n",
    "\n",
    "These functions handle sending images to Claude and processing the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structure_from_images(encoded_images, api_key, batch_size=5):\n",
    "    \"\"\"\n",
    "    Extract document structure from page images using Claude API.\n",
    "    Processes images in batches to handle API limits.\n",
    "    \n",
    "    Args:\n",
    "        encoded_images: List of dictionaries with page number and base64 data\n",
    "        api_key: Anthropic API key\n",
    "        batch_size: Number of images to process in each API call\n",
    "        \n",
    "    Returns:\n",
    "        DocumentStructure object\n",
    "    \"\"\"\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    \n",
    "    # Process images in batches\n",
    "    batches = [encoded_images[i:i+batch_size] for i in range(0, len(encoded_images), batch_size)]\n",
    "    all_headings = []\n",
    "    document_title = None\n",
    "    \n",
    "    for batch_index, batch in enumerate(batches):\n",
    "        print(f\"Processing batch {batch_index+1}/{len(batches)} (pages {batch[0]['page_number']}-{batch[-1]['page_number']})\")\n",
    "        \n",
    "        # Prepare message content\n",
    "        content = [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\"\"I'm sending you pages {batch[0]['page_number']}-{batch[-1]['page_number']} of a document. \n",
    "                Please identify all headings and their hierarchy in these pages by analyzing visual formatting cues:\n",
    "                \n",
    "                1. Look for section headings, indicated by larger font size, bold formatting, or numbering schemes (like 1., 1.1, A., etc.).\n",
    "                2. Determine the level of each heading based on visual prominence (text size, styling, indentation).\n",
    "                3. Level 1 should be the main headings, level 2 for subheadings, and so on.\n",
    "                4. If this is the first batch and you see a document title, please identify it.\n",
    "                \n",
    "                For each heading, provide:\n",
    "                - The exact text of the heading\n",
    "                - The heading level (1, 2, 3, etc.)\n",
    "                - The page number it appears on\n",
    "                \n",
    "                Respond in JSON format with an array of headings and document title if found.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Add images to the content\n",
    "        for img_data in batch:\n",
    "            content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/jpeg\",\n",
    "                    \"data\": img_data[\"base64\"]\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Call the API\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=4000,\n",
    "            temperature=0,  # Use 0 for consistent, deterministic output\n",
    "            system=\"You are an expert at document structure analysis. Your task is to identify the hierarchical structure of documents based on visual formatting cues like font size, style, indentation, and numbering systems. You will analyze document pages and extract the heading structure accurately. Respond with only JSON formatted data without explanations or markdown formatting.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        try:\n",
    "            # Extract JSON from the response\n",
    "            response_text = response.content[0].text\n",
    "            # Sometimes the API returns the JSON inside a code block, so remove that\n",
    "            json_text = re.sub(r'```json\\n(.+?)\\n```', r'\\1', response_text, flags=re.DOTALL)\n",
    "            json_text = re.sub(r'```(.+?)```', r'\\1', json_text, flags=re.DOTALL)\n",
    "            \n",
    "            result = json.loads(json_text)\n",
    "            \n",
    "            # Extract the headings from the result\n",
    "            if \"headings\" in result:\n",
    "                batch_headings = result[\"headings\"]\n",
    "                all_headings.extend(batch_headings)\n",
    "            \n",
    "            # Extract document title if this is the first batch\n",
    "            if batch_index == 0 and \"document_title\" in result and result[\"document_title\"]:\n",
    "                document_title = result[\"document_title\"]\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response from batch {batch_index+1}: {e}\")\n",
    "            print(f\"Response: {response.content[0].text}\")\n",
    "    \n",
    "    # Create the final document structure\n",
    "    structure = DocumentStructure(\n",
    "        headings=[HeadingElement(**h) for h in all_headings],\n",
    "        total_pages=len(encoded_images),\n",
    "        document_title=document_title\n",
    "    )\n",
    "    \n",
    "    return structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a Document\n",
    "\n",
    "Now let's use these functions to process a PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, output_path=None, max_pages=None):\n",
    "    \"\"\"\n",
    "    Process a PDF document to extract its structure.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        output_path: Path to save the output JSON (default: same as pdf with _structure.json)\n",
    "        max_pages: Maximum number of pages to process (None = all)\n",
    "        \n",
    "    Returns:\n",
    "        DocumentStructure object\n",
    "    \"\"\"\n",
    "    # Set default output path if not provided\n",
    "    if output_path is None:\n",
    "        output_path = Path(pdf_path).with_stem(f\"{Path(pdf_path).stem}_structure\").with_suffix(\".json\")\n",
    "    \n",
    "    # Convert PDF to images\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    \n",
    "    # Limit the number of pages if specified\n",
    "    if max_pages is not None:\n",
    "        images = images[:max_pages]\n",
    "        print(f\"Limited to first {max_pages} pages\")\n",
    "    \n",
    "    # Prepare images for API\n",
    "    encoded_images = prepare_images_for_api(images)\n",
    "    \n",
    "    # Extract structure\n",
    "    structure = extract_structure_from_images(encoded_images, ANTHROPIC_API_KEY)\n",
    "    \n",
    "    # Save the structure to JSON\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(structure.model_dump_json(indent=2))\n",
    "    \n",
    "    print(f\"\\nDocument structure saved to: {output_path}\")\n",
    "    \n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images: R35_MIRA.pdf\n",
      "Converted 11 pages\n",
      "Limited to first 25 pages\n",
      "Processing batch 1/3 (pages 1-5)\n",
      "Processing batch 2/3 (pages 6-10)\n",
      "Processing batch 3/3 (pages 11-11)\n",
      "\n",
      "Document structure saved to: R35_MIRA_structure.json\n",
      "\n",
      "Document Structure Summary:\n",
      "- Document title: None\n",
      "- Total pages processed: 11\n",
      "- Headings found: 14\n",
      "\n",
      "Heading Hierarchy:\n",
      "- A Background (Level 1, Page 1)\n",
      "- B Recent Research Progress (Level 1, Page 2)\n",
      "  - Helicase activation in the absence of DNA replication (Level 2, Page 2)\n",
      "  - Origin chromatin dynamics through multiple cell cycles (Level 2, Page 2)\n",
      "  - Modeling gene expression from chromatin occupancy data (Level 2, Page 2)\n",
      "  - Chromatin assembly behind the replication fork (Level 2, Page 2)\n",
      "  - Chromatin dynamics associated with double-strand break and repair (Level 2, Page 3)\n",
      "  - Collaborative work (Level 2, Page 3)\n",
      "- C Overview of Future Research (Level 1, Page 3)\n",
      "  - C.1 Chromatin assembly behind the fork (Level 2, Page 3)\n",
      "  - C.2 DNA replication and genome integrity (Level 2, Page 5)\n",
      "  - C.3 Gene regulation (Level 2, Page 6)\n",
      "  - C.4 Technology development (Level 2, Page 6)\n",
      "- Literature Cited (Level 1, Page 7)\n"
     ]
    }
   ],
   "source": [
    "# Enter the path to your PDF file\n",
    "#pdf_path = \"/home/davidm/Downloads/pstp_plan.pdf\"  # Replace with your PDF file\n",
    "pdf_path = \"R35_MIRA.pdf\"  # Replace with your PDF file\n",
    "\n",
    "# Process the document (limit to first 6 pages for testing)\n",
    "# Remove max_pages parameter to process the entire document\n",
    "if ANTHROPIC_API_KEY:\n",
    "    try:\n",
    "        structure = process_document(pdf_path, max_pages=25)\n",
    "        \n",
    "        # Display summary of the structure\n",
    "        print(f\"\\nDocument Structure Summary:\")\n",
    "        print(f\"- Document title: {structure.document_title}\")\n",
    "        print(f\"- Total pages processed: {structure.total_pages}\")\n",
    "        print(f\"- Headings found: {len(structure.headings)}\")\n",
    "        \n",
    "        # Display the heading hierarchy\n",
    "        print(\"\\nHeading Hierarchy:\")\n",
    "        for heading in structure.headings:\n",
    "            indent = \"  \" * (heading.level - 1)\n",
    "            print(f\"{indent}- {heading.text} (Level {heading.level}, Page {heading.page})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Cannot process document: No API key provided.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Structure\n",
    "\n",
    "Let's create a visualization of the document structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: None\n",
      "Total pages: 11\n",
      "\n",
      "Document Outline:\n",
      "\n",
      "--- Page 1 ---\n",
      "• A Background\n",
      "\n",
      "--- Page 2 ---\n",
      "• B Recent Research Progress\n",
      "  • Helicase activation in the absence of DNA replication\n",
      "  • Origin chromatin dynamics through multiple cell cycles\n",
      "  • Modeling gene expression from chromatin occupancy data\n",
      "  • Chromatin assembly behind the replication fork\n",
      "\n",
      "--- Page 3 ---\n",
      "  • Chromatin dynamics associated with double-strand break and repair\n",
      "  • Collaborative work\n",
      "• C Overview of Future Research\n",
      "  • C.1 Chromatin assembly behind the fork\n",
      "\n",
      "--- Page 5 ---\n",
      "  • C.2 DNA replication and genome integrity\n",
      "\n",
      "--- Page 6 ---\n",
      "  • C.3 Gene regulation\n",
      "  • C.4 Technology development\n",
      "\n",
      "--- Page 7 ---\n",
      "• Literature Cited\n"
     ]
    }
   ],
   "source": [
    "def create_structure_visualization(structure_path):\n",
    "    \"\"\"\n",
    "    Create a simple visualization of the document structure.\n",
    "    \n",
    "    Args:\n",
    "        structure_path: Path to the structure JSON file\n",
    "    \"\"\"\n",
    "    # Load the structure\n",
    "    with open(structure_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        structure_data = json.load(f)\n",
    "    \n",
    "    # Create a structure graph\n",
    "    print(f\"Document: {structure_data.get('document_title', 'Untitled')}\")\n",
    "    print(f\"Total pages: {structure_data['total_pages']}\")\n",
    "    print(\"\\nDocument Outline:\")\n",
    "    \n",
    "    # Show headings by level with page numbers\n",
    "    headings = sorted(structure_data[\"headings\"], key=lambda h: (h[\"page\"], h.get(\"position\", {}).get(\"y\", 0) if h.get(\"position\") else 0))\n",
    "    \n",
    "    current_page = None\n",
    "    for heading in headings:\n",
    "        # Show page breaks\n",
    "        if heading[\"page\"] != current_page:\n",
    "            current_page = heading[\"page\"]\n",
    "            print(f\"\\n--- Page {current_page} ---\")\n",
    "        \n",
    "        # Show the heading with indentation based on level\n",
    "        indent = \"  \" * (heading[\"level\"] - 1)\n",
    "        print(f\"{indent}• {heading['text']}\")\n",
    "\n",
    "# If we've already processed the document, visualize the structure\n",
    "structure_path = Path(pdf_path).with_stem(f\"{Path(pdf_path).stem}_structure\").with_suffix(\".json\")\n",
    "if structure_path.exists():\n",
    "    create_structure_visualization(structure_path)\n",
    "else:\n",
    "    print(f\"Structure file not found at {structure_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In Phase 2, we'll build on this foundation to:\n",
    "1. Apply the identified structure to OCR-extracted text\n",
    "2. Send both images and structured text to Claude\n",
    "3. Have Claude correct LaTeX, equations, and formatting issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
