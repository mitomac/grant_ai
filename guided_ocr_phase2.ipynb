{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided OCR with Format Correction (Phase 2)\n",
    "\n",
    "This notebook implements Phase 2 of our enhanced OCR process: applying the document structure and correcting specialized notation.\n",
    "\n",
    "## Steps:\n",
    "1. Load the structure data from Phase 1\n",
    "2. Process each page with its corresponding image and OCR text\n",
    "3. Apply heading structure based on structure data\n",
    "4. Correct specialized notation (LaTeX, equations, Greek symbols, etc.)\n",
    "5. Assemble the corrected pages into a final document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "import anthropic\n",
    "import re\n",
    "from pdf2image import convert_from_path\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import display, Image, Markdown\n",
    "from datetime import datetime\n",
    "import mistralai  # Optional - if using Mistral for OCR\n",
    "import pickle  # For caching intermediate results\n",
    "\n",
    "# Set your API key\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    print(\"Warning: No Anthropic API key found. Set the ANTHROPIC_API_KEY environment variable.\")\n",
    "    # Uncomment and set directly if needed\n",
    "    # ANTHROPIC_API_KEY = \"your_api_key_here\"\n",
    "\n",
    "# Optional: Mistral API key for OCR if not already done\n",
    "MISTRAL_API_KEY = os.environ.get(\"MISTRAL_OCR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "Let's define models for the document structure and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadingElement(BaseModel):\n",
    "    \"\"\"A heading element in the document\"\"\"\n",
    "    text: str = Field(..., description=\"The heading text\")\n",
    "    level: int = Field(..., description=\"Heading level (1 for main headings, 2 for subheadings, etc.)\")\n",
    "    page: int = Field(..., description=\"Page number containing the heading (1-indexed)\")\n",
    "    position: Optional[Dict[str, int]] = Field(None, description=\"Position coordinates on page (x, y, width, height)\")\n",
    "\n",
    "class DocumentStructure(BaseModel):\n",
    "    \"\"\"Structure of the document extracted from images\"\"\"\n",
    "    headings: List[HeadingElement] = Field(default_factory=list, description=\"All headings in the document\")\n",
    "    total_pages: int = Field(..., description=\"Total number of pages in the document\")\n",
    "    document_title: Optional[str] = Field(None, description=\"Title of the document\")\n",
    "\n",
    "class PageContent(BaseModel):\n",
    "    \"\"\"Content of a single page in the document\"\"\"\n",
    "    page_number: int = Field(..., description=\"Page number (1-indexed)\")\n",
    "    raw_text: str = Field(..., description=\"Raw OCR text from the page\")\n",
    "    headings: List[HeadingElement] = Field(default_factory=list, description=\"Headings on this page\")\n",
    "    corrected_text: Optional[str] = Field(None, description=\"Corrected text with proper structure and formatting\")\n",
    "\n",
    "class ProcessedDocument(BaseModel):\n",
    "    \"\"\"The fully processed document with structure and corrected content\"\"\"\n",
    "    title: Optional[str] = Field(None, description=\"Document title\")\n",
    "    pages: List[PageContent] = Field(default_factory=list, description=\"Content of each page\")\n",
    "    full_text: Optional[str] = Field(None, description=\"Complete assembled document text\")\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict, description=\"Additional metadata about the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF and Image Processing Functions\n",
    "\n",
    "Functions to handle PDF conversion and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, dpi=200, cache=True):\n",
    "    \"\"\"\n",
    "    Convert PDF to a list of PIL Image objects.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        dpi: Resolution for the images (higher = better quality but larger size)\n",
    "        cache: Whether to cache the results\n",
    "        \n",
    "    Returns:\n",
    "        List of PIL Image objects\n",
    "    \"\"\"\n",
    "    # Create cache directory if it doesn't exist\n",
    "    cache_dir = Path(\"cache\")\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate cache filename based on PDF path and DPI\n",
    "    pdf_name = Path(pdf_path).stem\n",
    "    cache_file = cache_dir / f\"{pdf_name}_images_{dpi}.pkl\"\n",
    "    \n",
    "    # Check if cached version exists\n",
    "    if cache and cache_file.exists():\n",
    "        print(f\"Loading images from cache: {cache_file}\")\n",
    "        with open(cache_file, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"Converting PDF to images: {pdf_path}\")\n",
    "    images = convert_from_path(pdf_path, dpi=dpi)\n",
    "    print(f\"Converted {len(images)} pages\")\n",
    "    \n",
    "    # Save to cache if enabled\n",
    "    if cache:\n",
    "        print(f\"Saving images to cache: {cache_file}\")\n",
    "        with open(cache_file, \"wb\") as f:\n",
    "            pickle.dump(images, f)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    \"\"\"\n",
    "    Encode a PIL Image to base64 for API transmission.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        \n",
    "    Returns:\n",
    "        Base64 encoded string\n",
    "    \"\"\"\n",
    "    import io\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def load_mistral_ocr_json(ocr_json_path):\n    \"\"\"\n    Load OCR results from Mistral's JSON format.\n    \n    Args:\n        ocr_json_path: Path to the OCR JSON file\n        \n    Returns:\n        List of dictionaries with page information including text and images\n    \"\"\"\n    with open(ocr_json_path, \"r\", encoding=\"utf-8\") as f:\n        ocr_data = json.load(f)\n    \n    pages = []\n    if \"pages\" in ocr_data:\n        for page_data in ocr_data[\"pages\"]:\n            # Extract the page index and markdown content\n            # The format is \"index=X markdown='content'\" with possible images list\n            match = re.search(r'index=(\\d+) markdown=[\\'\"](.+?)[\\'\"](?= images=|\\Z)', page_data, re.DOTALL)\n            if match:\n                page_index = int(match.group(1))\n                markdown_content = match.group(2)\n                \n                # Extract image info if present\n                images = []\n                img_match = re.search(r'images=\\[(.*?)\\]', page_data)\n                if img_match and img_match.group(1):\n                    # Parse the image information\n                    img_data = img_match.group(1)\n                    img_objects = re.finditer(r'OCRImageObject\\(id=[\\'\"](.*?)[\\'\"](.*?)\\)', img_data)\n                    for img_obj in img_objects:\n                        img_id = img_obj.group(1)\n                        coords_str = img_obj.group(2)\n                        \n                        # Extract coordinates\n                        top_left_x = re.search(r'top_left_x=(\\d+)', coords_str)\n                        top_left_y = re.search(r'top_left_y=(\\d+)', coords_str)\n                        bottom_right_x = re.search(r'bottom_right_x=(\\d+)', coords_str)\n                        bottom_right_y = re.search(r'bottom_right_y=(\\d+)', coords_str)\n                        \n                        images.append({\n                            \"id\": img_id,\n                            \"coordinates\": {\n                                \"top_left_x\": int(top_left_x.group(1)) if top_left_x else None,\n                                \"top_left_y\": int(top_left_y.group(1)) if top_left_y else None,\n                                \"bottom_right_x\": int(bottom_right_x.group(1)) if bottom_right_x else None,\n                                \"bottom_right_y\": int(bottom_right_y.group(1)) if bottom_right_y else None,\n                            }\n                        })\n                \n                # Get page dimensions if present\n                dimensions = {}\n                dim_match = re.search(r'dimensions=OCRPageDimensions\\(([^)]+)\\)', page_data)\n                if dim_match:\n                    dim_str = dim_match.group(1)\n                    dpi_match = re.search(r'dpi=(\\d+)', dim_str)\n                    height_match = re.search(r'height=(\\d+)', dim_str)\n                    width_match = re.search(r'width=(\\d+)', dim_str)\n                    \n                    dimensions = {\n                        \"dpi\": int(dpi_match.group(1)) if dpi_match else None,\n                        \"height\": int(height_match.group(1)) if height_match else None,\n                        \"width\": int(width_match.group(1)) if width_match else None\n                    }\n                \n                pages.append({\n                    \"index\": page_index,\n                    \"markdown\": markdown_content,\n                    \"images\": images,\n                    \"dimensions\": dimensions\n                })\n    \n    # Sort pages by index\n    pages.sort(key=lambda x: x[\"index\"])\n    return pages",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def get_ocr_text(pdf_path, api_key=None, use_cached=True):\n    \"\"\"\n    Get OCR text from a PDF, either from cache or from Mistral API.\n    Prioritizes loading from the OCR JSON file if it exists.\n    \n    Args:\n        pdf_path: Path to the PDF file\n        api_key: Mistral API key (if not using cached results)\n        use_cached: Whether to use cached results if available\n        \n    Returns:\n        Tuple of (list of page dictionaries, full combined text)\n    \"\"\"\n    # Check for cached OCR JSON file\n    ocr_json_path = Path(pdf_path).with_suffix(\".ocr.json\")\n    if use_cached and ocr_json_path.exists():\n        print(f\"Using cached OCR data from: {ocr_json_path}\")\n        pages = load_mistral_ocr_json(ocr_json_path)\n        \n        # Combine all pages into a single text\n        full_text = \"\\n\\n\".join(page[\"markdown\"] for page in pages)\n        return pages, full_text\n    \n    # Check for cached markdown file as fallback\n    markdown_path = Path(pdf_path).with_suffix(\".md\")\n    if use_cached and markdown_path.exists():\n        print(f\"Using cached OCR text from: {markdown_path}\")\n        with open(markdown_path, \"r\", encoding=\"utf-8\") as f:\n            text = f.read()\n            # Create a simulated page structure\n            pages = split_text_into_pages(text)\n            return pages, text\n    \n    # If not using cache or no cache available, use Mistral API\n    if not api_key:\n        raise ValueError(\"No Mistral API key provided and no cached text available\")\n        \n    print(f\"Performing OCR on: {pdf_path}\")\n    \n    # Use Mistral API to perform OCR\n    # This is a simplified version - see the full implementation in Phase 1\n    client = mistralai.Mistral(api_key=api_key)\n    \n    # Upload file\n    uploaded_pdf = client.files.upload(\n        file={\n            \"file_name\": Path(pdf_path).name,\n            \"content\": open(pdf_path, \"rb\"),\n        },\n        purpose=\"ocr\"\n    )\n    \n    # Get signed URL\n    signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n    \n    # Process OCR\n    ocr_response = client.ocr.process(\n        model=\"mistral-ocr-latest\",\n        document={\n            \"type\": \"document_url\",\n            \"document_url\": signed_url.url,\n        }\n    )\n    \n    # Save raw response for future use\n    with open(ocr_json_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(ocr_response, f, indent=2, default=str)\n    \n    # Load the saved JSON (ensures consistency with cached loads)\n    pages = load_mistral_ocr_json(ocr_json_path)\n    full_text = \"\\n\\n\".join(page[\"markdown\"] for page in pages)\n    \n    # Also save the markdown for compatibility\n    with open(markdown_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(full_text)\n    \n    return pages, full_text\n\ndef split_text_into_pages(full_text):\n    \"\"\"\n    Split text into simulated pages.\n    Used as a fallback when we only have the plain text without page information.\n    \n    Args:\n        full_text: Complete OCR text from the document\n        \n    Returns:\n        List of page dictionaries with markdown content\n    \"\"\"\n    # Try to detect page breaks based on common patterns\n    page_texts = re.split(r'\\n\\s*[-]{3,}\\s*[Pp]age\\s+\\d+\\s*[-]{3,}\\s*\\n', full_text)\n    \n    # If that didn't work well, try another approach\n    if len(page_texts) <= 1:\n        # Try to find major section breaks (lines starting with # )\n        page_texts = re.split(r'\\n\\s*#\\s+[A-Z]', full_text)\n        \n        # Put the # back at the beginning of each section (except the first)\n        for i in range(1, len(page_texts)):\n            page_texts[i] = '# ' + page_texts[i]\n        \n        # If still not good, just split into roughly equal parts\n        if len(page_texts) <= 1:\n            # Estimate 2000 characters per page\n            chars_per_page = 2000\n            page_texts = [full_text[i:i+chars_per_page] \n                          for i in range(0, len(full_text), chars_per_page)]\n    \n    # Convert to page dictionaries\n    pages = []\n    for i, text in enumerate(page_texts):\n        pages.append({\n            \"index\": i,\n            \"markdown\": text.strip(),\n            \"images\": [],\n            \"dimensions\": {}\n        })\n    \n    return pages"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Loading and Processing\n",
    "\n",
    "Functions to load and process the structure data from Phase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document_structure(structure_path):\n",
    "    \"\"\"\n",
    "    Load the document structure from a JSON file created in Phase 1.\n",
    "    \n",
    "    Args:\n",
    "        structure_path: Path to the structure JSON file\n",
    "        \n",
    "    Returns:\n",
    "        DocumentStructure object\n",
    "    \"\"\"\n",
    "    with open(structure_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        structure_data = json.load(f)\n",
    "    \n",
    "    return DocumentStructure(**structure_data)\n",
    "\n",
    "def get_page_headings(structure, page_number):\n",
    "    \"\"\"\n",
    "    Get headings for a specific page from the document structure.\n",
    "    \n",
    "    Args:\n",
    "        structure: DocumentStructure object\n",
    "        page_number: Page number (1-indexed)\n",
    "        \n",
    "    Returns:\n",
    "        List of HeadingElement objects for the specified page\n",
    "    \"\"\"\n",
    "    return [h for h in structure.headings if h.page == page_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction Functions with Claude API\n",
    "\n",
    "Functions to process pages with Claude, applying structure and fixing notation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def correct_page_content(page_number, image, raw_text, headings, api_key, document_title=None, context=None):\n    \"\"\"\n    Process a single page with Claude to apply structure and correct formatting.\n    \n    Args:\n        page_number: Page number (1-indexed)\n        image: PIL Image object of the page\n        raw_text: Raw OCR text from the page\n        headings: List of HeadingElement objects for this page\n        api_key: Anthropic API key\n        document_title: Optional document title for context\n        context: Optional surrounding context (text from adjacent pages)\n        \n    Returns:\n        Corrected text with proper structure and formatting\n    \"\"\"\n    client = anthropic.Anthropic(api_key=api_key)\n    \n    # Prepare the heading information string\n    heading_info = \"\\n\".join([f\"- '{h.text}': level {h.level} (# {'#' * (h.level - 1)})\" for h in headings])\n    if not heading_info:\n        heading_info = \"No headings detected on this page.\"\n    \n    # Encode the image for API transmission\n    image_base64 = encode_image_to_base64(image)\n    \n    # Prepare the instruction text\n    instruction = f\"\"\"\n    I'm sending you page {page_number} of a scientific document{' titled \"' + document_title + '\"' if document_title else ''}. \n    \n    The following headings have been identified on this page:\n    {heading_info}\n    \n    Here's the raw OCR text extracted from this page:\n    ```\n    {raw_text}\n    ```\n    \n    Please:\n    \n    1. Apply the correct markdown heading levels to all headings identified above.\n    \n    2. Fix LaTeX formatting consistently throughout the document:\n       - Make sure all citations have proper LaTeX syntax: e.g., \"$^{{1,2}}$\" not \"^1,2\"\n       - Ensure all mathematical expressions are properly wrapped in $ symbols\n       - Fix superscripts and subscripts with proper LaTeX syntax\n       - Make sure there are no spaces inside the LaTeX delimiters for citations\n       - Ensure all citation numbers are properly formatted with curly braces: \"$^{{1}}$\" not \"$^1$\"\n    \n    3. Fix specific LaTeX issues:\n       - Fix expressions like \"${{ }}^{{21}}$\" to \"$^{{21}}$\"\n       - Fix histone notations like \"(H3-H4)2\" to \"$(H3-H4)_2$\"\n       - Fix spacing in math expressions by removing excess spaces\n       - Fix nucleosome size notation like \"~147 bp\" to \"~147 \\\\text{{bp}}\"\n       - Ensure all units are in \\\\text{{}} format: \"\\\\text{{kb}}\", \"\\\\text{{bp}}\", etc.\n    \n    4. Fix formatting of gene names, protein names, and other scientific notation:\n       - Italicize gene names when appropriate\n       - Make sure protein complexes are formatted correctly (e.g., \"Mcm2-7\")\n    \n    5. Preserve paragraph structure and ensure text flows properly without any strange formatting artifacts.\n    \n    Return ONLY the corrected markdown text without any explanations or additional commentary.\n    \"\"\"\n    \n    # Add context if provided\n    if context:\n        instruction += f\"\"\"\n        \n        For context, here's text from adjacent pages (do not include this in your response):\n        ```\n        {context}\n        ```\n        \"\"\"\n    \n    # Prepare message content\n    content = [\n        {\"type\": \"text\", \"text\": instruction},\n        {\n            \"type\": \"image\",\n            \"source\": {\n                \"type\": \"base64\",\n                \"media_type\": \"image/jpeg\",\n                \"data\": image_base64\n            }\n        }\n    ]\n    \n    # Call the API\n    response = client.messages.create(\n        model=\"claude-3-opus-20240229\",  # Using the highest quality model for better text processing\n        max_tokens=4000,\n        temperature=0,  # Use 0 for consistent, deterministic output\n        system=\"You are an expert at scientific document formatting, especially LaTeX notation in markdown. Your task is to ensure all LaTeX formatting is consistent and correct throughout the document. This includes ensuring all citations are properly formatted with $ delimiters and curly braces, all mathematical expressions are properly wrapped in $ symbols, and all superscripts and subscripts use proper LaTeX syntax. Pay special attention to citation numbers, ensuring they're formatted as $^{N}$ consistently. Only return the corrected text without explanations.\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": content\n            }\n        ]\n    )\n    \n    # Post-process the response to ensure consistent LaTeX formatting\n    corrected_text = response.content[0].text.strip()\n    \n    # Ensure citations are properly formatted\n    # Replace ^{N} without $ with $^{N}$\n    corrected_text = re.sub(r'([^$])(\\^{[0-9,\\s-]+})', r'\\1$\\2$', corrected_text)\n    \n    # Ensure there are no spaces inside citation LaTeX\n    corrected_text = re.sub(r'\\$\\^\\{\\s*([0-9,\\s-]+)\\s*\\}\\$', r'$^{\\1}$', corrected_text)\n    \n    # Remove spaces between citation numbers\n    corrected_text = re.sub(r'\\$\\^\\{([0-9]+)\\s*,\\s*([0-9,\\s-]+)\\}\\$', r'$^{\\1,\\2}$', corrected_text)\n    \n    return corrected_text"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Assembly and Processing\n",
    "\n",
    "Functions to process the entire document and assemble the corrected pages."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def process_document_with_structure(pdf_path, structure_path, output_path=None, max_pages=None):\n    \"\"\"\n    Process a PDF document using the structure from Phase 1, correcting formatting and notation.\n    \n    Args:\n        pdf_path: Path to the PDF file\n        structure_path: Path to the structure JSON file from Phase 1\n        output_path: Path to save the output markdown (default: same as pdf with _structured.md)\n        max_pages: Maximum number of pages to process (None = all)\n        \n    Returns:\n        ProcessedDocument object\n    \"\"\"\n    # Set default output path if not provided\n    if output_path is None:\n        output_path = Path(pdf_path).with_stem(f\"{Path(pdf_path).stem}_structured\").with_suffix(\".md\")\n    \n    # Load the document structure\n    structure = load_document_structure(structure_path)\n    \n    # Convert PDF to images\n    images = convert_pdf_to_images(pdf_path)\n    \n    # Limit the number of pages if specified\n    if max_pages is not None:\n        images = images[:max_pages]\n        print(f\"Limited to first {max_pages} pages\")\n    \n    # Get OCR text using direct JSON loading\n    ocr_pages, full_text = get_ocr_text(pdf_path, api_key=MISTRAL_API_KEY)\n    \n    # Make sure we have the same number of OCR pages and images\n    if len(ocr_pages) != len(images):\n        print(f\"Warning: Number of OCR pages ({len(ocr_pages)}) doesn't match number of images ({len(images)})\")\n        # Adjust to the smaller number\n        min_pages = min(len(ocr_pages), len(images))\n        ocr_pages = ocr_pages[:min_pages]\n        images = images[:min_pages]\n        print(f\"Proceeding with {min_pages} pages\")\n    \n    # Process each page\n    processed_pages = []\n    corrected_texts = []\n    \n    for i, (image, page_data) in enumerate(zip(images, ocr_pages)):\n        page_number = i + 1  # 1-indexed\n        print(f\"Processing page {page_number}/{len(images)}...\")\n        \n        # Get headings for this page\n        page_headings = get_page_headings(structure, page_number)\n        \n        # Get context from adjacent pages\n        context = None\n        if i > 0 and i < len(ocr_pages) - 1:\n            context = f\"Previous page: {ocr_pages[i-1]['markdown'][:500]}...\\n\\nNext page: {ocr_pages[i+1]['markdown'][:500]}...\"\n        elif i > 0:\n            context = f\"Previous page: {ocr_pages[i-1]['markdown'][:500]}...\"\n        elif i < len(ocr_pages) - 1:\n            context = f\"Next page: {ocr_pages[i+1]['markdown'][:500]}...\"\n        \n        # Extract image references for this page\n        page_images = page_data.get(\"images\", [])\n        image_info = \"\"\n        if page_images:\n            image_info = \"\\n\\nThis page contains the following images:\\n\"\n            for img in page_images:\n                image_info += f\"- Image ID: {img['id']}\\n\"\n                if \"coordinates\" in img:\n                    coords = img[\"coordinates\"]\n                    image_info += f\"  Located at position: ({coords.get('top_left_x')}, {coords.get('top_left_y')}) to ({coords.get('bottom_right_x')}, {coords.get('bottom_right_y')})\\n\"\n        \n        # Correct the page content\n        corrected_text = correct_page_content(\n            page_number, \n            image, \n            page_data[\"markdown\"] + image_info, \n            page_headings, \n            ANTHROPIC_API_KEY,\n            document_title=structure.document_title,\n            context=context\n        )\n        \n        # Create PageContent object\n        page_content = PageContent(\n            page_number=page_number,\n            raw_text=page_data[\"markdown\"],\n            headings=[HeadingElement(\n                text=h.text,\n                level=h.level,\n                page=h.page,\n                position=h.position\n            ) for h in page_headings],\n            corrected_text=corrected_text\n        )\n        \n        processed_pages.append(page_content)\n        corrected_texts.append(corrected_text)\n        \n        # Optional: Save intermediate results\n        cache_dir = Path(\"cache\")\n        cache_dir.mkdir(exist_ok=True)\n        with open(cache_dir / f\"{Path(pdf_path).stem}_page_{page_number}.md\", \"w\", encoding=\"utf-8\") as f:\n            f.write(corrected_text)\n    \n    # Assemble the final document\n    assembled_text = \"\\n\\n\".join(corrected_texts)\n    \n    # Create ProcessedDocument object\n    document = ProcessedDocument(\n        title=structure.document_title,\n        pages=processed_pages,\n        full_text=assembled_text,\n        metadata={\n            \"source_file\": str(pdf_path),\n            \"structure_file\": str(structure_path),\n            \"processed_date\": datetime.now().isoformat(),\n            \"total_pages\": len(processed_pages)\n        }\n    )\n    \n    # Save the assembled document\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(assembled_text)\n    \n    print(f\"\\nAssembled document saved to: {output_path}\")\n    \n    # Save the full processed document data\n    json_output_path = Path(output_path).with_suffix(\".json\")\n    with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(document.model_dump_json(indent=2))\n    \n    print(f\"Full document data saved to: {json_output_path}\")\n    \n    return document"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a Document\n",
    "\n",
    "Now let's use these functions to process a sample document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to your PDF file and structure file from Phase 1\n",
    "pdf_path = \"R35_MIRA.pdf\"  # Replace with your PDF file\n",
    "structure_path = f\"{Path(pdf_path).stem}_structure.json\"  # From Phase 1\n",
    "\n",
    "# Process the document (limit to first 3 pages for testing)\n",
    "# Remove max_pages parameter to process the entire document\n",
    "if ANTHROPIC_API_KEY and Path(structure_path).exists():\n",
    "    try:\n",
    "        document = process_document_with_structure(\n",
    "            pdf_path=pdf_path,\n",
    "            structure_path=structure_path,\n",
    "            max_pages=3  # Comment this out to process all pages\n",
    "        )\n",
    "        \n",
    "        # Display summary of the processed document\n",
    "        print(f\"\\nProcessed Document Summary:\")\n",
    "        print(f\"- Document title: {document.title}\")\n",
    "        print(f\"- Total pages processed: {len(document.pages)}\")\n",
    "        print(f\"- Output size: {len(document.full_text)} characters\")\n",
    "        \n",
    "        # Display a preview of the results\n",
    "        preview_length = min(500, len(document.full_text))\n",
    "        print(f\"\\nPreview of the first {preview_length} characters:\")\n",
    "        display(Markdown(document.full_text[:preview_length] + \"...\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    if not ANTHROPIC_API_KEY:\n",
    "        print(\"Cannot process document: No API key provided.\")\n",
    "    if not Path(structure_path).exists():\n",
    "        print(f\"Cannot process document: Structure file not found at {structure_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Original and Corrected Text\n",
    "\n",
    "Let's visualize the improvements by comparing original and corrected text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def compare_original_and_corrected(page_number, document):\n    \"\"\"\n    Display a side-by-side comparison of original and corrected text for a page.\n    \n    Args:\n        page_number: Page number to compare (1-indexed)\n        document: ProcessedDocument object or dictionary loaded from JSON\n    \"\"\"\n    # Find the page - handle both object and dictionary formats\n    if hasattr(document, 'pages'):\n        # Case when document is an object\n        page = next((p for p in document.pages if p.page_number == page_number), None)\n    else:\n        # Case when document is a dictionary (loaded from JSON)\n        pages = document.get('pages', [])\n        page = next((p for p in pages if p.get('page_number') == page_number), None)\n    \n    if not page:\n        print(f\"Page {page_number} not found in the processed document.\")\n        return\n    \n    # Get text content - handle both object and dictionary formats\n    if hasattr(page, 'raw_text'):\n        raw_text = page.raw_text\n        corrected_text = page.corrected_text\n    else:\n        raw_text = page.get('raw_text', '')\n        corrected_text = page.get('corrected_text', '')\n    \n    # Display comparison\n    print(f\"Page {page_number} - Original vs. Corrected Text:\\n\")\n    \n    # Create HTML for side-by-side display\n    html = f\"\"\"\n    <div style=\"display: flex;\">\n        <div style=\"flex: 1; padding: 10px; border: 1px solid #ccc;\">\n            <h3>Original Text</h3>\n            <pre>{raw_text}</pre>\n        </div>\n        <div style=\"flex: 1; padding: 10px; border: 1px solid #ccc;\">\n            <h3>Corrected Text</h3>\n            <pre>{corrected_text}</pre>\n        </div>\n    </div>\n    \"\"\"\n    \n    from IPython.display import HTML\n    display(HTML(html))\n\n    # Also show the rendered markdown for corrected text\n    print(\"\\nRendered Corrected Text:\")\n    display(Markdown(corrected_text))\n\n# If we've processed a document, compare the first page\njson_output_path = Path(pdf_path).with_stem(f\"{Path(pdf_path).stem}_structured\").with_suffix(\".json\")\nif json_output_path.exists():\n    with open(json_output_path, \"r\", encoding=\"utf-8\") as f:\n        doc_data = json.load(f)\n    \n    # Compare the first page\n    if 'pages' in doc_data and len(doc_data['pages']) > 0:\n        compare_original_and_corrected(1, doc_data)\nelse:\n    print(f\"Processed document not found at {json_output_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this Phase 2 notebook, we've built a system that:\n",
    "\n",
    "1. Uses the structure information from Phase 1\n",
    "2. Processes each page with both its image and OCR text\n",
    "3. Applies the correct heading structure\n",
    "4. Corrects specialized notation (LaTeX, equations, Greek symbols)\n",
    "5. Assembles the pages into a well-structured final document\n",
    "\n",
    "The approach uses Claude's multimodal capabilities to understand both the visual appearance and text content of each page, resulting in much better structure and formatting than traditional OCR alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}