{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation Evaluation\n",
    "\n",
    "This notebook evaluates how well citations support scientific claims by:\n",
    "1. Loading citation data and references from the JSON file\n",
    "2. Using an LLM to determine if the referenced content supports each claim\n",
    "3. Evaluating multiple citations holistically when present\n",
    "4. Saving the evaluation results to evaluation.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Optional, Any\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference(BaseModel):\n",
    "    \"\"\"Reference information\"\"\"\n",
    "    reference_id: int = Field(..., description=\"The ID of the reference\")\n",
    "    reference_text: str = Field(..., description=\"The full text of the reference\")\n",
    "\n",
    "class ClaimEvaluation(BaseModel):\n",
    "    \"\"\"Evaluation of whether citations support a claim\"\"\"\n",
    "    claim_text: str = Field(..., description=\"The text of the claim\")\n",
    "    citation_keys: List[int] = Field(..., description=\"Citation keys supporting this claim\")\n",
    "    citation_text: str = Field(..., description=\"Original citation text (e.g., '$^{1,2}$')\")\n",
    "    references: List[Reference] = Field(..., description=\"Full reference information for citations\")\n",
    "    is_adequately_supported: bool = Field(..., description=\"Whether the claim is adequately supported by its citations\")\n",
    "    explanation: str = Field(..., description=\"Explanation of why the citations do or don't support the claim\")\n",
    "    suggestions: Optional[List[str]] = Field(None, description=\"Suggestions for improving the citation support\")\n",
    "\n",
    "class EvaluationResults(BaseModel):\n",
    "    \"\"\"Overall evaluation results for a document\"\"\"\n",
    "    document_id: str = Field(..., description=\"ID of the document being evaluated\")\n",
    "    evaluations: List[ClaimEvaluation] = Field(..., description=\"List of claim evaluations\")\n",
    "    processed_date: str = Field(..., description=\"Date and time of evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Citation Data and References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 81 citations and 81 references from document: R35_MIRA_document\n",
      "Single citation claims: 60\n",
      "Multiple citation claims: 21\n"
     ]
    }
   ],
   "source": [
    "# Load citations and references data from JSON file\n",
    "citation_json_path = \"citation_analysis/citations.json\"\n",
    "\n",
    "with open(citation_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "document_id = data['document_id']\n",
    "citations = data['citations']\n",
    "references = data.get('references', [])\n",
    "\n",
    "# Create a reference lookup dictionary\n",
    "reference_dict = {}\n",
    "for ref in references:\n",
    "    reference_dict[ref['reference_id']] = ref['reference_text']\n",
    "\n",
    "print(f\"Loaded {len(citations)} citations and {len(references)} references from document: {document_id}\")\n",
    "\n",
    "# Count single vs multiple citation claims\n",
    "single_citations = sum(1 for c in citations if len(c['citation_keys']) == 1)\n",
    "multi_citations = sum(1 for c in citations if len(c['citation_keys']) > 1)\n",
    "print(f\"Single citation claims: {single_citations}\")\n",
    "print(f\"Multiple citation claims: {multi_citations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_claim(claim_data, reference_dict, references_list, client, model=\"gpt-4.1\"):\n",
    "    \"\"\"\n",
    "    Evaluate if citations support a claim.\n",
    "    \n",
    "    Args:\n",
    "        claim_data: Dictionary with claim information and citations\n",
    "        reference_dict: Dictionary mapping reference IDs to reference text\n",
    "        references_list: List of all reference objects\n",
    "        client: OpenAI client\n",
    "        model: Model to use for evaluation\n",
    "        \n",
    "    Returns:\n",
    "        ClaimEvaluation object\n",
    "    \"\"\"\n",
    "    # Extract claim information\n",
    "    claim_text = claim_data['claim']\n",
    "    citation_text = claim_data['citation_text']\n",
    "    citation_keys = claim_data['citation_keys']\n",
    "    \n",
    "    # Get the referenced content for each citation key\n",
    "    reference_content = \"\"\n",
    "    for i, key in enumerate(citation_keys):\n",
    "        ref_text = reference_dict.get(key, \"Reference content not found\")\n",
    "        reference_content += f\"Reference {i+1} (#{key}): {ref_text}\\n\\n\"\n",
    "    \n",
    "    # Get the full reference objects for these citation keys\n",
    "    claim_references = []\n",
    "    for key in citation_keys:\n",
    "        ref_obj = next((r for r in references_list if r['reference_id'] == key), None)\n",
    "        if ref_obj:\n",
    "            claim_references.append(Reference(\n",
    "                reference_id=ref_obj['reference_id'],\n",
    "                reference_text=ref_obj['reference_text']\n",
    "            ))\n",
    "    \n",
    "    # Response model for the LLM\n",
    "    class EvaluationResponse(BaseModel):\n",
    "        is_adequately_supported: bool = Field(..., description=\"Whether the claim is adequately supported by its citations\")\n",
    "        explanation: str = Field(..., description=\"Explanation of why the citations do or don't support the claim\")\n",
    "        suggestions: Optional[List[str]] = Field(None, description=\"Suggestions for improving the citation support\")\n",
    "    \n",
    "    # System prompt for claim evaluation\n",
    "    system_prompt = \"\"\"\n",
    "    You are a citation evaluation expert with extensive knowledge of scientific literature and academic standards.\n",
    "    Your task is to assess whether a scientific claim is adequately supported by its citations.\n",
    "    \n",
    "    IMPORTANT: When a claim has multiple citations, evaluate them HOLISTICALLY as a group,\n",
    "    not just individually. Consider how they work together to support the overall claim.\n",
    "    \"\"\"\n",
    "    \n",
    "    # User prompt for evaluation\n",
    "    user_prompt = f\"\"\"\n",
    "    Evaluate whether this scientific claim is adequately supported by its citations.\n",
    "    \n",
    "    CLAIM:\n",
    "    \"{claim_text}\"\n",
    "    \n",
    "    This claim is supported by {len(citation_keys)} citation(s) appearing as: {citation_text}\n",
    "    \n",
    "    CITED REFERENCES:\n",
    "    {reference_content}\n",
    "    \n",
    "    Based on the content of these references, provide an evaluation with:\n",
    "    1. Is this claim adequately supported by these references? (Yes/No)\n",
    "    2. Explain your reasoning in detail\n",
    "    3. If support is inadequate, provide 1-2 suggestions for improvement\n",
    "    \n",
    "    If there are multiple references, remember to evaluate them HOLISTICALLY, considering\n",
    "    how they work together rather than just evaluating them individually.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use structured output to get evaluation\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EvaluationResponse\n",
    "        )\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = completion.choices[0].message.parsed\n",
    "        \n",
    "        # Create the full evaluation object\n",
    "        evaluation = ClaimEvaluation(\n",
    "            claim_text=claim_text,\n",
    "            citation_keys=citation_keys,\n",
    "            citation_text=citation_text,\n",
    "            references=claim_references,\n",
    "            is_adequately_supported=response.is_adequately_supported,\n",
    "            explanation=response.explanation,\n",
    "            suggestions=response.suggestions\n",
    "        )\n",
    "        \n",
    "        return evaluation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating claim: {e}\")\n",
    "        \n",
    "        # Return a default evaluation in case of error\n",
    "        return ClaimEvaluation(\n",
    "            claim_text=claim_text,\n",
    "            citation_keys=citation_keys,\n",
    "            citation_text=citation_text,\n",
    "            references=claim_references,\n",
    "            is_adequately_supported=True,\n",
    "            explanation=f\"Error evaluating claim: {str(e)}\"\n",
    "        )\n",
    "\n",
    "def evaluate_all_claims(citations, reference_dict, references_list, api_key, output_path=\"citation_analysis/evaluation.json\"):\n",
    "    \"\"\"\n",
    "    Evaluate all claims and save results to JSON.\n",
    "    \n",
    "    Args:\n",
    "        citations: List of citation dictionaries\n",
    "        reference_dict: Dictionary mapping reference IDs to reference text\n",
    "        references_list: List of all reference objects\n",
    "        api_key: OpenAI API key\n",
    "        output_path: Path to save evaluation results\n",
    "        \n",
    "    Returns:\n",
    "        EvaluationResults object with all evaluations\n",
    "    \"\"\"\n",
    "    # Create OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    # Evaluate each claim\n",
    "    evaluations = []\n",
    "    total_claims = len(citations)\n",
    "    \n",
    "    for i, claim in enumerate(citations):\n",
    "        print(f\"Evaluating claim {i+1}/{total_claims}: {claim['claim'][:80]}...\" if len(claim['claim']) > 80 else f\"Evaluating claim {i+1}/{total_claims}: {claim['claim']}\")\n",
    "        \n",
    "        # Evaluate the claim\n",
    "        evaluation = evaluate_claim(claim, reference_dict, references_list, client)\n",
    "        evaluations.append(evaluation)\n",
    "        \n",
    "        # Show abbreviated result\n",
    "        result = \"Adequately supported\" if evaluation.is_adequately_supported else \"Inadequately supported\"\n",
    "        print(f\"Result: {result}\\n\")\n",
    "        \n",
    "        # Save intermediate results every 10 claims\n",
    "        if (i+1) % 10 == 0:\n",
    "            intermediate_results = EvaluationResults(\n",
    "                document_id=document_id,\n",
    "                evaluations=evaluations,\n",
    "                processed_date=datetime.now().isoformat()\n",
    "            )\n",
    "            \n",
    "            # Save to temporary file\n",
    "            temp_path = output_path.replace(\".json\", \"_partial.json\")\n",
    "            with open(temp_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(intermediate_results.model_dump_json(indent=2))\n",
    "            print(f\"Saved intermediate results ({i+1}/{total_claims} claims) to {temp_path}\")\n",
    "    \n",
    "    # Create final results object\n",
    "    results = EvaluationResults(\n",
    "        document_id=document_id,\n",
    "        evaluations=evaluations,\n",
    "        processed_date=datetime.now().isoformat()\n",
    "    )\n",
    "    \n",
    "    # Save results to JSON file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(results.model_dump_json(indent=2))\n",
    "    \n",
    "    print(f\"\\nEvaluation complete. All results saved to {output_path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation on All Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating claim 1/81: Duplication of the genome, once and only once per cell cycle, is accomplished by...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 2/81: The origin recognition complex (ORC) bound to defined origin sequences in the bu...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 3/81: Helicase loading is restricted to G1 and, in effect, 'licenses' the origin for a...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 4/81: DDK and CDK promote the recruitment of additional proteins including Cdc45 and t...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 5/81: Helicase progression and coupling with the replisome at each fork is a tightly r...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 6/81: Helicase uncoupling can be induced by a number of mechanisms including limiting ...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 7/81: Chemical inhibition of polymerases can induce helicase uncoupling.\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 8/81: Lesions that block the replisome, but not the helicase, can induce helicase unco...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 9/81: If unchecked, helicase uncoupling can lead to significant DNA unwinding resultin...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 10/81: In the absence of replication priming by Pol α/primase, the CMG helicase complex...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Saved intermediate results (10/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 11/81: Failure to completely copy the genome may result in a catastrophic failure to se...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 12/81: The formation of chromosome bridges and micronuclei is associated with chromothr...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 13/81: Mechanisms to resolve and repair unreplicated gaps during mitosis may occur from...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 14/81: Unreplicated gaps during mitosis may occur at the latest replicating sequences.\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 15/81: A consequence of uncoupling the helicase from DNA synthesis at origins is the ge...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 16/81: Replication-coupled chromatin assembly is critical for preserving epigenetic mem...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 17/81: The local chromatin environment influences the extent of local inheritance, with...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 18/81: Many histone chaperones are involved in the deposition of nascent and parental h...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 19/81: We are beginning to understand how histone chaperones facilitate deposition to e...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 20/81: Asymmetric histone inheritance is observed in Drosophila male germ line stem cel...\n",
      "Result: Adequately supported\n",
      "\n",
      "Saved intermediate results (20/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 21/81: We developed and continue to extend genome-wide chromatin occupancy profiling (G...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 22/81: This assay reveals specific footprints for more than 70% of the yeast DNA-bindin...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 23/81: the chromatin occupancy dynamics associated with the initiation of DNA replicati...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 24/81: gene expression in response to an environmental stress\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 25/81: DNA repair by non-homologous end joining\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 26/81: the re-assembly of chromatin behind the replication fork\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 27/81: blocked replication priming at the non-permissive conditions\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 28/81: generated GCOPS for synchronized yeast cells as they progressed through two comp...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 29/81: included the strength of ORC binding\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 30/81: included the numbers of Mcm2-7 loaded at origins\n",
      "Result: Adequately supported\n",
      "\n",
      "Saved intermediate results (30/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 31/81: included the rate limiting concentrations of origin firing components\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 32/81: captured chromatin occupancy and gene expression data under conditions of heavy ...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 33/81: developed RoboCOP to jointly compute a robust probability estimate for nucleosom...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 34/81: assessed the spatiotemporal dynamics of chromatin assembly behind the DNA replic...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 35/81: investigated chromatin dynamics following induction of a site-specific double-st...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 36/81: used maximum depth sequencing to identify initiating oncogenic mutations in RAS ...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 37/81: identified oncogenic mutations in RAS alleles with extreme sensitivity (~1 mutat...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 38/81: characterized the replication timing of sequences and the role of repressive chr...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 39/81: demonstrated that active transcription of a RNA pol II noncoding transcript at t...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 40/81: supported prior work demonstrating plasticity in origin selection by transcripti...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Saved intermediate results (40/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 41/81: supported work from the Remus lab demonstrating plasticity in origin selection b...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 42/81: Chromatin assembly on nascent DNA is a complex and regulated process that is cri...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 43/81: The Caf-1 complex is involved in the replication-dependent deposition of nascent...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 44/81: Loss of CAC1 results in defects in silencing.\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 45/81: Loss of CAC1 leads to increased sensitivity to DNA damage.\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 46/81: Loss of CAC1 leads to elevated cryptic transcription.\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 47/81: Despite the phenotypes associated with loss of CAC1, there are very little obser...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 48/81: Biochemical and structural studies suggest that the Caf1 complex, while not requ...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 49/81: Deletion of the K/E/R and WHD domains of Cac1 is used to test the hypothesis tha...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 50/81: The cac1 Δ phenotype of elevated cryptic transcription is hypothesized to arise ...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Saved intermediate results (50/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 51/81: TSS-seq is used to capture the 5' capped end of nascent mRNAs to test the hypoth...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 52/81: Mcm2 functions as one of the replisome components acting as a histone chaperone ...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 53/81: Pol ε functions as a replisome component acting as a histone chaperone at the re...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 54/81: Pol α functions as a replisome component acting as a histone chaperone at the re...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 55/81: RPA functions as a replisome component acting as a histone chaperone at the repl...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 56/81: In a mcm2-3A mutant, there is a relative increase in parental (H3-H4)2 tetramers...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 57/81: Prior ChIP based methodologies such as eSPAN have been used to study strand-spec...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 58/81: Uncoupling of the helicase from active DNA replication can result in the generat...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 59/81: Uncoupling of the helicase from active DNA replication can also lead to replicat...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 60/81: The allele cdc17-ts-FRB was used to prevent RNA priming by Pol α/primase, thereb...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Saved intermediate results (60/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 61/81: The CMG helicase complex stalled in regions of elevated GC content relative to t...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 62/81: Rad53 has been linked to helicase speed and fork progression.\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 63/81: Rad53 has been linked to limiting helicase uncoupling.\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 64/81: No difference in helicase progression was observed in the absence of MRC1 and ac...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 65/81: Early reports on DNA unwinding in Pol α and primase mutants observed significant...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 66/81: Rad53 regulated helicase uncoupling is independent of its interaction with Cdc45...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 67/81: ChIP-seq will be used to assess the recruitment of Rad53 to sites of helicase un...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 68/81: Cells with restored priming experienced a prolonged delay in G2/M due to the pre...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 69/81: The unreplicated gaps at origins are structurally similar to DNA intermediates p...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 70/81: In vitro work from the Labib group found that Pif1 was required for the terminat...\n",
      "Result: Adequately supported\n",
      "\n",
      "Saved intermediate results (70/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 71/81: Gene regulatory networks have been inferred from the analysis of gene expression...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 72/81: ChIP based approaches to identify the binding sites of specific TFs are prone to...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 73/81: These locus specific chromatin changes independent of gene expression may serve ...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 74/81: We have continued to develop and extend our GCOP assay to describe the chromatin...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 75/81: Recent advances in next generation long read technologies (e.g. Nanopore, PacBio...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 76/81: Recent advances in next generation long read technologies (e.g. Nanopore, PacBio...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 77/81: Long read sequencing coupled with the detection of m6A methylation led to the de...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 78/81: Historically, the very first locus specific protein DNA occupancy maps were gene...\n",
      "Result: Adequately supported\n",
      "\n",
      "Evaluating claim 79/81: More recently, DMS-seq was developed to map chromatin accessibility following th...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Evaluating claim 80/81: Our long time collaborator, Alex Hartemink, has experience developing statistica...\n",
      "Result: Inadequately supported\n",
      "\n",
      "Saved intermediate results (80/81 claims) to citation_analysis/evaluation_partial.json\n",
      "Evaluating claim 81/81: Alex Hartemink has developed robust sequence based models for chromatin occupanc...\n",
      "Result: Inadequately supported\n",
      "\n",
      "\n",
      "Evaluation complete. All results saved to citation_analysis/evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# Check if OpenAI API key is available\n",
    "if not openai_api_key:\n",
    "    print(\"Warning: No OpenAI API key provided. Set the OPENAI_API_KEY environment variable.\")\n",
    "else:\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(\"citation_analysis\").mkdir(exist_ok=True)\n",
    "    \n",
    "    # Evaluate all claims and save results\n",
    "    results = evaluate_all_claims(citations, reference_dict, references, openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total claims evaluated: 81\n",
      "Adequately supported: 51 (63.0%)\n",
      "Inadequately supported: 30 (37.0%)\n",
      "\n",
      "Single citation claims: 60\n",
      "Adequately supported: 51.7%\n",
      "\n",
      "Multiple citation claims: 21\n",
      "Adequately supported: 95.2%\n",
      "\n",
      "Claims with improvement suggestions: 31\n",
      "Total improvement suggestions: 59\n"
     ]
    }
   ],
   "source": [
    "def analyze_results(results):\n",
    "    \"\"\"Analyze evaluation results\"\"\"\n",
    "    evaluations = results.evaluations\n",
    "    \n",
    "    # Basic statistics\n",
    "    total = len(evaluations)\n",
    "    adequately_supported = sum(1 for e in evaluations if e.is_adequately_supported)\n",
    "    inadequately_supported = total - adequately_supported\n",
    "    \n",
    "    print(f\"Total claims evaluated: {total}\")\n",
    "    print(f\"Adequately supported: {adequately_supported} ({adequately_supported/total:.1%})\")\n",
    "    print(f\"Inadequately supported: {inadequately_supported} ({inadequately_supported/total:.1%})\")\n",
    "    \n",
    "    # Single vs multiple citation comparison\n",
    "    single_citation_claims = [e for e in evaluations if len(e.citation_keys) == 1]\n",
    "    multi_citation_claims = [e for e in evaluations if len(e.citation_keys) > 1]\n",
    "    \n",
    "    # Calculate adequacy rates\n",
    "    single_citation_adequacy = sum(1 for e in single_citation_claims if e.is_adequately_supported) / len(single_citation_claims) if single_citation_claims else 0\n",
    "    multi_citation_adequacy = sum(1 for e in multi_citation_claims if e.is_adequately_supported) / len(multi_citation_claims) if multi_citation_claims else 0\n",
    "    \n",
    "    print(f\"\\nSingle citation claims: {len(single_citation_claims)}\")\n",
    "    print(f\"Adequately supported: {single_citation_adequacy:.1%}\")\n",
    "    \n",
    "    print(f\"\\nMultiple citation claims: {len(multi_citation_claims)}\")\n",
    "    print(f\"Adequately supported: {multi_citation_adequacy:.1%}\")\n",
    "    \n",
    "    # Suggestions count\n",
    "    claims_with_suggestions = sum(1 for e in evaluations if e.suggestions and len(e.suggestions) > 0)\n",
    "    total_suggestions = sum(len(e.suggestions) for e in evaluations if e.suggestions)\n",
    "    \n",
    "    print(f\"\\nClaims with improvement suggestions: {claims_with_suggestions}\")\n",
    "    print(f\"Total improvement suggestions: {total_suggestions}\")\n",
    "\n",
    "# Load and analyze results if file exists\n",
    "evaluation_path = \"citation_analysis/evaluation.json\"\n",
    "if Path(evaluation_path).exists():\n",
    "    with open(evaluation_path, 'r', encoding='utf-8') as f:\n",
    "        saved_results = json.load(f)\n",
    "    \n",
    "    # Convert to EvaluationResults object\n",
    "    results = EvaluationResults.model_validate(saved_results)\n",
    "    analyze_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
