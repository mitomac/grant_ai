{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Based Citation Extraction \n",
    "\n",
    "This notebook handles extraction of citations from scientific documents:\n",
    "1. Loading the processed document from JSON\n",
    "2. Using an LLM to extract citations section-by-section\n",
    "3. For each citation, identifying:\n",
    "   - The scientific claim being supported\n",
    "   - The citation text\n",
    "   - Expanded citation keys\n",
    "   - The paragraph context\n",
    "4. Saving the structured citation data for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, Any, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Define Data Models\n\nWe'll use Pydantic models to structure our citation data.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "class ExtractedCitation(BaseModel):\n    \"\"\"A citation extracted by the LLM with expanded citation keys\"\"\"\n    claim: str = Field(..., description=\"The scientific claim being made and supported by the citation\")\n    citation_text: str = Field(..., description=\"The exact LaTeX citation text (e.g., '$^{1}$' or '$^{2-5}$')\")\n    citation_keys: List[int] = Field(..., description=\"Expanded list of citation keys as integers\")\n    paragraph: str = Field(..., description=\"The paragraph containing the citation for context\")\n    section_id: str = Field(..., description=\"ID of the section containing the citation\")\n\nclass Reference(BaseModel):\n    \"\"\"A reference from the bibliography\"\"\"\n    reference_id: int = Field(..., description=\"The numeric ID of the reference (e.g., 1 from [1])\")\n    reference_text: str = Field(..., description=\"The full text of the reference\")\n    pmcid: Optional[str] = Field(None, description=\"PMCID if present in the reference\")\n\nclass ReferenceList(BaseModel):\n    \"\"\"List of references extracted from the bibliography\"\"\"\n    references: List[Reference] = Field(..., description=\"List of references extracted from the bibliography\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "class CitationAnalysisResults(BaseModel):\n    \"\"\"Results of the citation extraction process\"\"\"\n    document_id: str = Field(..., description=\"ID of the processed document\")\n    citations: List[ExtractedCitation] = Field(..., description=\"Citations extracted from the document\")\n    total_citations: int = Field(..., description=\"Total number of citations extracted\")\n    citations_by_section: Dict[str, int] = Field(..., description=\"Count of citations by section ID\")\n    references: Optional[List[Reference]] = Field(None, description=\"References extracted from the bibliography\")\n    processed_date: str = Field(..., description=\"Date the analysis was performed\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "class LLMCitationExtractor:\n    \"\"\"\n    Uses LLM to extract citations from document sections with expanded citation keys\n    \"\"\"\n    \n    def __init__(self, api_key=None, model=\"gpt-4.1\"):\n        \"\"\"Initialize with OpenAI API key\"\"\"\n        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"OpenAI API key is required\")\n        \n        self.client = OpenAI(api_key=self.api_key)\n        self.model = model\n        \n    def extract_citations_from_section(self, section_id, section_title, section_content):\n        \"\"\"\n        Extract citations from a single section using LLM with expanded citation keys\n        \n        Args:\n            section_id: ID of the section\n            section_title: Title of the section\n            section_content: Content of the section\n            \n        Returns:\n            List of ExtractedCitation objects\n        \"\"\"\n        # DEBUG: Print section info to verify data is being sent to the LLM\n        print(f\"DEBUG: Processing section_id={section_id}, title='{section_title}'\")\n        print(f\"DEBUG: Content sample: {section_content[:100]}...\")\n        \n        # Define a model for the response format\n        class CitationResponse(BaseModel):\n            citations: List[ExtractedCitation] = Field(\n                default_factory=list,\n                description=\"Extracted citations with their claims, citation text, expanded keys, and paragraph context\"\n            )\n        \n        # Define the prompt for citation extraction\n        prompt = f\"\"\"\n        You are an expert at identifying citations in scientific papers. Analyze the following section of text and extract all citations with their context.\n\n        SECTION: {section_title}\n\n        TEXT:\n        ```\n        {section_content}\n        ```\n\n        TASK:\n        1. Identify ALL citation callouts that match these LaTeX patterns:\n           - $^{{n}}$ (Single citation, e.g., $^{{1}}$)\n           - $^{{m-n}}$ (Range citation, e.g., $^{{2-5}}$)\n           - $^{{a,b,c}}$ (List citation, e.g., $^{{6,7,8}}$)\n           - $^{{a-b,c,d-e}}$ (Complex citation, e.g., $^{{2-4,7,9-10}}$)\n           - Any variations with spaces like ${{ }}^{{1}}$\n\n        2. For each citation, extract:\n           - The scientific claim being supported by the citation\n           - The exact citation text as it appears (e.g., \"$^{{2-5}}$\")\n           - The citation keys, expanded to individual numbers:\n              * For a range like \"2-5\", expand to [2,3,4,5]\n              * For a list like \"6,7,8\", expand to [6,7,8]\n              * For complex citations like \"2-4,7,9-10\", expand to [2,3,4,7,9,10]\n           - The full paragraph containing the citation for context\n           \n        IMPORTANT: Be sure to check figure captions for citations as well.\n        \"\"\"\n        \n        try:\n            # Use the parse method to get structured output directly into our Pydantic model\n            completion = self.client.beta.chat.completions.parse(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a citation extraction specialist. Extract all citation callouts from scientific texts with high precision.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                response_format=CitationResponse\n            )\n            \n            # Get the extracted citations directly from the parsed response\n            extracted_citations = completion.choices[0].message.parsed.citations\n            \n            # Set the section_id for all extracted citations\n            for citation in extracted_citations:\n                citation.section_id = section_id\n            \n            print(f\"Extracted {len(extracted_citations)} citations from section '{section_title}'\")\n            return extracted_citations\n            \n        except Exception as e:\n            print(f\"Error extracting citations from section '{section_title}': {e}\")\n            return []\n    \n    def extract_all_citations(self, document_data):\n        \"\"\"\n        Extract all citations from document sections\n        \n        Args:\n            document_data: Processed document data from JSON\n            \n        Returns:\n            List of ExtractedCitation objects\n        \"\"\"\n        all_citations = []\n        processed_section_ids = set()  # Track sections we've processed\n        \n        # Process all sections and their subsections\n        def process_section(section, parent_id=\"\"):\n            section_id = section['section_id']\n            processed_section_ids.add(section_id)\n            \n            # Skip the bibliography/references section\n            if any(ref_term in section['title'].lower() for ref_term in ['literature cited', 'references', 'bibliography']):\n                print(f\"Skipping bibliography section: {section['title']}\")\n                return\n            \n            # Extract citations from this section\n            section_citations = self.extract_citations_from_section(\n                section_id, \n                section['title'], \n                section['content']\n            )\n            all_citations.extend(section_citations)\n            \n            # Process subsections recursively\n            if 'subsections' in section and section['subsections']:\n                for subsection in section['subsections']:\n                    process_section(subsection, section_id)\n        \n        # Process all top-level sections\n        for section in document_data['sections']:\n            process_section(section)\n        \n        # Process figure captions\n        if 'figures' in document_data:\n            for figure in document_data['figures']:\n                figure_id = figure['figure_id']\n                caption = figure['caption']\n                \n                # Extract citations from the figure caption\n                caption_citations = self.extract_citations_from_section(\n                    figure_id,\n                    f\"Figure {figure.get('figure_number', '')}\",\n                    caption\n                )\n                all_citations.extend(caption_citations)\n                processed_section_ids.add(figure_id)\n        \n        print(f\"Extracted {len(all_citations)} total citations from document using LLM\")\n        return all_citations, processed_section_ids"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def analyze_citations_with_llm(document_json_path, openai_api_key=None):\n    \"\"\"\n    Extract and analyze citations in a document using LLM.\n    \n    Args:\n        document_json_path: Path to the processed document JSON file\n        openai_api_key: OpenAI API key (optional, will use environment variable if not provided)\n        \n    Returns:\n        CitationAnalysisResults object\n    \"\"\"\n    # Load the document data\n    with open(document_json_path, 'r', encoding='utf-8') as f:\n        document_data = json.load(f)\n    \n    document_id = Path(document_json_path).stem\n    \n    print(f\"Processing document: {document_id}\")\n    \n    # Extract citations using LLM\n    print(\"\\n=== EXTRACTING CITATIONS USING LLM ===\")\n    extractor = LLMCitationExtractor(api_key=openai_api_key)\n    citations, processed_section_ids = extractor.extract_all_citations(document_data)\n    \n    # Count citations by section\n    citations_by_section = {}\n    \n    # Initialize counts for all processed sections (even those with zero citations)\n    for section_id in processed_section_ids:\n        citations_by_section[section_id] = 0\n    \n    # Count citations for each section\n    for citation in citations:\n        section_id = citation.section_id\n        citations_by_section[section_id] = citations_by_section.get(section_id, 0) + 1\n    \n    # Extract bibliography references\n    references = extract_bibliography(document_data, openai_api_key)\n    \n    # Create the results object\n    results = CitationAnalysisResults(\n        document_id=document_id,\n        citations=citations,\n        total_citations=len(citations),\n        citations_by_section=citations_by_section,\n        references=references,\n        processed_date=datetime.now().isoformat()\n    )\n    \n    # Print summary statistics\n    print(\"\\n===== CITATION ANALYSIS SUMMARY =====\")\n    print(f\"Total citations extracted: {results.total_citations}\")\n    print(f\"Total references extracted: {len(references)}\")\n    \n    print(\"\\nCitation distribution by section:\")\n    # Get section titles from document data\n    section_titles = {}\n    \n    def collect_section_titles(section, parent_title=\"\"):\n        section_id = section['section_id']\n        section_title = section['title']\n        section_titles[section_id] = section_title\n        \n        if 'subsections' in section and section['subsections']:\n            for subsection in section['subsections']:\n                collect_section_titles(subsection, section_title)\n    \n    # Collect section titles from document data\n    for section in document_data['sections']:\n        collect_section_titles(section)\n    \n    # Add figure captions to section titles\n    if 'figures' in document_data:\n        for figure in document_data['figures']:\n            figure_id = figure['figure_id']\n            section_titles[figure_id] = f\"Figure {figure.get('figure_number', '')}\"\n    \n    # Print citation counts by section with titles\n    for section_id, count in sorted(citations_by_section.items(), key=lambda x: x[1], reverse=True):\n        section_title = section_titles.get(section_id, \"Unknown\")\n        print(f\"  - {section_title}: {count} citations\")\n    \n    return results"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def save_citation_results(results, output_dir='citation_analysis'):\n    \"\"\"\n    Save the citation analysis results to files.\n    \n    Args:\n        results: CitationAnalysisResults object\n        output_dir: Directory to save the files\n    \"\"\"\n    # Create directory if it doesn't exist\n    output_path = Path(output_dir)\n    output_path.mkdir(exist_ok=True, parents=True)\n    \n    # Save the complete results as JSON\n    with open(output_path / 'citations.json', 'w', encoding='utf-8') as f:\n        f.write(results.model_dump_json(indent=2))\n    \n    # Save citations as CSV\n    citations_df = pd.DataFrame([{\n        'claim': citation.claim,\n        'citation_text': citation.citation_text,\n        'citation_keys': ','.join(map(str, citation.citation_keys)),\n        'section_id': citation.section_id,\n        'paragraph_length': len(citation.paragraph) \n    } for citation in results.citations])\n    \n    citations_df.to_csv(output_path / 'citations.csv', index=False)\n    \n    # Save references as CSV if available\n    if results.references:\n        references_df = pd.DataFrame([{\n            'reference_id': ref.reference_id,\n            'reference_text': ref.reference_text,\n            'pmcid': ref.pmcid or ''\n        } for ref in results.references])\n        \n        references_df.to_csv(output_path / 'bibliography.csv', index=False)\n        print(f\"Saved {len(results.references)} references to {output_path}/bibliography.csv\")\n    \n    print(f\"\\nAnalysis results saved to {output_path}/\")\n    \n    return citations_df"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def extract_bibliography(document_data, openai_api_key=None):\n    \"\"\"\n    Extract structured bibliography from document.\n    \n    Args:\n        document_data: Processed document data from JSON\n        openai_api_key: OpenAI API key (optional, will use environment variable if not provided)\n        \n    Returns:\n        List of Reference objects\n    \"\"\"\n    # Find the bibliography section\n    bibliography_section = None\n    for section in document_data['sections']:\n        if any(ref_term in section['title'].lower() for ref_term in ['literature cited', 'references', 'bibliography']):\n            bibliography_section = section\n            break\n    \n    if not bibliography_section:\n        print(\"Bibliography section not found\")\n        return []\n    \n    # Get the bibliography text\n    bibliography_text = bibliography_section['content']\n    \n    print(f\"\\n=== EXTRACTING BIBLIOGRAPHY ===\")\n    print(f\"Processing bibliography section: {bibliography_section['title']}\")\n    \n    # Use the LLM to extract references\n    client = OpenAI(api_key=openai_api_key or os.environ.get(\"OPENAI_API_KEY\"))\n    \n    prompt = f\"\"\"\n    Parse this bibliography into a structured format with the following fields:\n    \n    1. reference_id: The numeric ID of the reference (e.g., 1 from [1])\n    2. reference_text: The full text of the reference\n    3. pmcid: Extract any PMCID if present (e.g., \"PMC1234567\"), otherwise leave empty\n    \n    Bibliography:\n    ```\n    {bibliography_text}\n    ```\n    \n    IMPORTANT:\n    - Make sure to extract ALL references\n    - Capture the entire reference text, including any URLs or DOIs\n    - Pay special attention to extracting PMCIDs correctly\n    - If there are no PMCIDs, it's fine to leave them empty\n    - Verify that the reference numbers form a complete sequence (1,2,3,...) with no gaps\n    \"\"\"\n    \n    try:\n        completion = client.beta.chat.completions.parse(\n            model=\"gpt-4.1\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an expert at parsing academic bibliographies into structured data.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            response_format=ReferenceList\n        )\n        \n        references = completion.choices[0].message.parsed.references\n        \n        # Verify we have all references in sequence\n        extracted_ids = sorted([ref.reference_id for ref in references])\n        expected_ids = list(range(1, max(extracted_ids) + 1))\n        \n        if extracted_ids != expected_ids:\n            missing_ids = set(expected_ids) - set(extracted_ids)\n            print(f\"WARNING: Missing references: {missing_ids}\")\n        \n        print(f\"Extracted {len(references)} references from bibliography\")\n        return references\n        \n    except Exception as e:\n        print(f\"Error extracting bibliography: {e}\")\n        return []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Enter the path to your processed document JSON\ndocument_json_path = \"R35_MIRA_document.json\"\n\n# Enter your OpenAI API key here or set it as an environment variable\nopenai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n\ntry:\n    # Check if the document JSON exists\n    if not Path(document_json_path).exists():\n        print(f\"Document JSON not found at {document_json_path}\")\n        print(\"Run the ocr.ipynb notebook first to create the document JSON.\")\n    elif not openai_api_key:\n        print(\"OpenAI API key not provided. Set the OPENAI_API_KEY environment variable or provide it directly.\")\n    else:\n        # Analyze the document's citations using LLM\n        results = analyze_citations_with_llm(document_json_path, openai_api_key)\n        \n        # Save the results\n        citations_df = save_citation_results(results)\n        \n        # Display a sample of the results\n        print(\"\\n=== SAMPLE OF EXTRACTED CITATIONS ===\")\n        print(citations_df.head())\n        \n        # Print some example claims and their citation keys\n        print(\"\\n=== EXAMPLE CLAIMS WITH EXPANDED CITATION KEYS ===\")\n        for i, citation in enumerate(results.citations[:5]):  # Show first 5 citations\n            print(f\"\\n{i+1}. Claim: {citation.claim[:100]}...\" if len(citation.claim) > 100 else f\"\\n{i+1}. Claim: {citation.claim}\")\n            print(f\"   Citation: {citation.citation_text}\")\n            print(f\"   Expanded keys: {citation.citation_keys}\")\n        \n        # Print sample of extracted references if available\n        if results.references:\n            print(\"\\n=== SAMPLE OF EXTRACTED REFERENCES ===\")\n            for i, ref in enumerate(results.references[:5]):  # Show first 5 references\n                print(f\"\\n{i+1}. Reference ID: {ref.reference_id}\")\n                print(f\"   Text: {ref.reference_text[:100]}...\" if len(ref.reference_text) > 100 else f\"   Text: {ref.reference_text}\")\n                if ref.pmcid:\n                    print(f\"   PMCID: {ref.pmcid}\")\n        \nexcept Exception as e:\n    print(f\"Error analyzing document: {e}\")\n    import traceback\n    traceback.print_exc()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "## Conclusion\n\nIn this notebook, we:\n1. Loaded the processed document from JSON\n2. Used an LLM to extract citations section-by-section\n3. For each citation, the LLM:\n   - Identified the scientific claim being supported\n   - Extracted the exact citation text\n   - Expanded citation keys (ranges and lists) into individual numbers\n   - Captured the surrounding paragraph for context\n4. Extracted bibliography references with PMCIDs when available\n5. Saved the structured citation data for further analysis\n\nThe LLM-based approach provides a more intelligent extraction of citations by understanding the context and automatically handling the expansion of citation ranges and lists. This eliminates the need for complex regex patterns and separate post-processing steps, resulting in more accurate identification of claims and their supporting citations.\n\n### Future Improvements\n\n- **Document Structure Enhancement**: When processing markdown for the document structure JSON, add a specific flag for bibliography sections to make them easier to identify and skip during citation extraction.\n- **Subsection Processing Optimization**: Improve how subsections are processed to ensure more efficient citation extraction throughout the document hierarchy.\n- **Citation Pattern Recognition**: Further refine the LLM prompt to handle various citation formats including uncommon LaTeX variations.\n- **Bibliography Chunking**: If bibliography extraction completeness is an issue, implement a chunking strategy to process larger bibliographies.\n- **PMCID Validation**: Add additional validation for PMCIDs, including format checking and verification."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}